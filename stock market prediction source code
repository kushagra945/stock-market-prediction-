
#importing necessary libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
#importing the dataset

df = pd.read_csv('apple.csv')
df.tail()
symbol	date	close	high	low	open	volume	adjClose	adjHigh	adjLow	adjOpen	adjVolume	divCash	splitFactor
1252	AAPL	2023-06-15 00:00:00+00:00	186.01	186.520	183.7800	183.96	65433166	186.01	186.520	183.7800	183.96	65433166	0.0	1.0
1253	AAPL	2023-06-16 00:00:00+00:00	184.92	186.990	184.2700	186.73	101256225	184.92	186.990	184.2700	186.73	101256225	0.0	1.0
1254	AAPL	2023-06-20 00:00:00+00:00	185.01	186.100	184.4100	184.41	49799092	185.01	186.100	184.4100	184.41	49799092	0.0	1.0
1255	AAPL	2023-06-21 00:00:00+00:00	183.96	185.410	182.5901	184.90	49515697	183.96	185.410	182.5901	184.90	49515697	0.0	1.0
1256	AAPL	2023-06-22 00:00:00+00:00	187.00	187.045	183.6700	183.74	51245327	187.00	187.045	183.6700	183.74	51245327	0.0	1.0
df1 = df.reset_index()['close']
df1.shape
(1257,)
#displaying how the close values are distributed
plt.plot(df['close'])
[<matplotlib.lines.Line2D at 0x1fe9c8b5960>]

#scaling down the values between (0,1)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))
#it has now transformed into an array containing values between 0 and 1
print(df1)
[[0.18867877]
 [0.19433939]
 [0.19366312]
 ...
 [0.19579211]
 [0.19316218]
 [0.20077646]]
Preprocessing Data
train_len = int(len(df1)*0.65)        #65% of dataset is used as training dataset
test_len = int(len(df1)-train_len)    #rest of dataset is used as testing dataset


train_data = df1[0:train_len:]
test_data = df1[train_len:len(df1):1]
train_len,test_len
(817, 440)
len(train_data),len(test_data)
(817, 440)
#convert array of values into a dataset matrix
def create_dataset(dataset,time_step = 1):
    dataX,dataY = [],[]
    for i in range(len(dataset)-time_step - 1):
        a = dataset[i:(i+time_step),0]
        dataX.append(a)
        dataY.append(dataset[i + time_step, 0])
    return np.array(dataX),np.array(dataY)
time_step = 100
x_train,y_train = create_dataset(train_data,time_step)
x_test,y_test = create_dataset(test_data,time_step)
print(x_train.shape),print(y_train.shape)
(716, 100)
(716,)
(None, None)
print(x_test.shape),print(y_test.shape)
(339, 100)
(339,)
(None, None)
Creating a stacked LSTM Model
#reshaping the x_train and x_test data into 3-Dimension

#reshpae input to be [sample, time steps, features] which is required for LSTM

x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)    #The last '1' with comma makes it 3-D
x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)
#Creating a stacked LSTM model

model = Sequential()
model.add(LSTM(50,return_sequences = True, input_shape = (100,1)))
model.add(LSTM(50,return_sequences = True))
model.add(LSTM(50))
model.add(Dense(1))
model.compile(loss = 'mean_squared_error', optimizer = 'adam')
model.summary()
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 100, 50)           10400     
                                                                 
 lstm_1 (LSTM)               (None, 100, 50)           20200     
                                                                 
 lstm_2 (LSTM)               (None, 50)                20200     
                                                                 
 dense (Dense)               (None, 1)                 51        
                                                                 
=================================================================
Total params: 50,851
Trainable params: 50,851
Non-trainable params: 0
_________________________________________________________________
model.fit(x_train,y_train, validation_data=(x_test,y_test),epochs=50, batch_size=64, verbose=1)
Epoch 1/50
12/12 [==============================] - 1s 115ms/step - loss: 0.0105 - val_loss: 3.9130e-04
Epoch 2/50
12/12 [==============================] - 1s 115ms/step - loss: 0.0092 - val_loss: 3.6630e-04
Epoch 3/50
12/12 [==============================] - 1s 115ms/step - loss: 0.0083 - val_loss: 3.2495e-04
Epoch 4/50
12/12 [==============================] - 1s 117ms/step - loss: 0.0076 - val_loss: 6.8092e-04
Epoch 5/50
12/12 [==============================] - 1s 118ms/step - loss: 0.0067 - val_loss: 6.3753e-04
Epoch 6/50
12/12 [==============================] - 1s 116ms/step - loss: 0.0065 - val_loss: 5.9655e-04
Epoch 7/50
12/12 [==============================] - 1s 118ms/step - loss: 0.0063 - val_loss: 5.9825e-04
Epoch 8/50
12/12 [==============================] - 1s 111ms/step - loss: 0.0050 - val_loss: 2.9315e-04
Epoch 9/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0070 - val_loss: 2.8390e-04
Epoch 10/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0048 - val_loss: 2.8521e-04
Epoch 11/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0038 - val_loss: 3.1192e-04
Epoch 12/50
12/12 [==============================] - 1s 111ms/step - loss: 0.0037 - val_loss: 3.6716e-04
Epoch 13/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0038 - val_loss: 4.3260e-04
Epoch 14/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0031 - val_loss: 3.6562e-04
Epoch 15/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0030 - val_loss: 2.7398e-04
Epoch 16/50
12/12 [==============================] - 1s 111ms/step - loss: 0.0052 - val_loss: 5.4974e-04
Epoch 17/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0044 - val_loss: 2.4170e-04
Epoch 18/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0038 - val_loss: 3.3478e-04
Epoch 19/50
12/12 [==============================] - 1s 111ms/step - loss: 0.0032 - val_loss: 3.9458e-04
Epoch 20/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0025 - val_loss: 2.6605e-04
Epoch 21/50
12/12 [==============================] - 1s 114ms/step - loss: 0.0025 - val_loss: 5.0070e-04
Epoch 22/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0062 - val_loss: 3.8760e-04
Epoch 23/50
12/12 [==============================] - 1s 111ms/step - loss: 0.0064 - val_loss: 0.0010
Epoch 24/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0062 - val_loss: 2.6667e-04
Epoch 25/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0044 - val_loss: 8.0158e-04
Epoch 26/50
12/12 [==============================] - 1s 114ms/step - loss: 0.0040 - val_loss: 2.5448e-04
Epoch 27/50
12/12 [==============================] - 1s 115ms/step - loss: 0.0031 - val_loss: 2.5594e-04
Epoch 28/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0028 - val_loss: 2.4490e-04
Epoch 29/50
12/12 [==============================] - 1s 114ms/step - loss: 0.0028 - val_loss: 2.3377e-04
Epoch 30/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0028 - val_loss: 2.3143e-04
Epoch 31/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0029 - val_loss: 2.7606e-04
Epoch 32/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0024 - val_loss: 2.7150e-04
Epoch 33/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0021 - val_loss: 3.0713e-04
Epoch 34/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0020 - val_loss: 2.1046e-04
Epoch 35/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0020 - val_loss: 2.3479e-04
Epoch 36/50
12/12 [==============================] - 1s 114ms/step - loss: 0.0019 - val_loss: 2.6700e-04
Epoch 37/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0019 - val_loss: 2.6032e-04
Epoch 38/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0024 - val_loss: 2.7160e-04
Epoch 39/50
12/12 [==============================] - 1s 111ms/step - loss: 0.0021 - val_loss: 2.9976e-04
Epoch 40/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0023 - val_loss: 4.9005e-04
Epoch 41/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0018 - val_loss: 2.6014e-04
Epoch 42/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0016 - val_loss: 2.3136e-04
Epoch 43/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0028 - val_loss: 2.4892e-04
Epoch 44/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0034 - val_loss: 2.2498e-04
Epoch 45/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0027 - val_loss: 3.4977e-04
Epoch 46/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0023 - val_loss: 2.7739e-04
Epoch 47/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0043 - val_loss: 3.0776e-04
Epoch 48/50
12/12 [==============================] - 1s 112ms/step - loss: 0.0034 - val_loss: 9.2509e-04
Epoch 49/50
12/12 [==============================] - 1s 113ms/step - loss: 0.0023 - val_loss: 2.8931e-04
Epoch 50/50
12/12 [==============================] - 1s 114ms/step - loss: 0.0019 - val_loss: 2.1371e-04
<keras.callbacks.History at 0x1fead02d4e0>
#predicting and checking performance metrics

train_predict = model.predict(x_train)
test_predict = model.predict(x_test)
23/23 [==============================] - 1s 22ms/step
11/11 [==============================] - 0s 21ms/step
#transform back to original form
#because the data we have scaled down needs to be get in original form

train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)
import math
from sklearn.metrics import mean_squared_error
#calculate RMSE performance metrics for train data

math.sqrt(mean_squared_error(y_train,train_predict))
224.60130386473094
#test data RMSE

math.sqrt(mean_squared_error(y_test,test_predict))
156.72323372882516
Plotting the prediction
#shift train prediction for plotting
look_back = 100
trainPredictPlot = np.empty_like(df1)
trainPredictPlot[:,:] = np.nan
trainPredictPlot[look_back:len(train_predict)+look_back, : ] = train_predict
#shift test predictions for plotting
testPredictPlot = np.empty_like(df1)
testPredictPlot[:,:] = np.nan
testPredictPlot[len(train_predict)+(look_back*2)+1 : len(df1)-1, : ] = test_predict
#plot baseline and predictions
plt.plot(scaler.inverse_transform(df1))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()

len(test_data)
440
#Last date of our data is 22/6. To predict for 23/6 we need to study previous 100 days data (assume)

440-100
340
x_input = test_data[340:].reshape(1,-1)
x_input.shape
(1, 100)
temp_input = list(x_input)
temp_input = temp_input[0].tolist()
temp_input
[0.09056981840951783,
 0.0938008766437069,
 0.09665623043206006,
 0.11015654351909826,
 0.11937382592360674,
 0.1124358171571696,
 0.11974953036944269,
 0.11291170945522849,
 0.11028177833437691,
 0.1106324358171571,
 0.11774577332498432,
 0.11611772072636184,
 0.12145272385723233,
 0.11739511584220413,
 0.11448966812773947,
 0.10429555416405756,
 0.10537257357545393,
 0.10659987476518468,
 0.09986224170319347,
 0.10289292423293667,
 0.10161552911709448,
 0.09635566687539132,
 0.09785848465873509,
 0.11068252974326859,
 0.11769567939887288,
 0.11211020663744514,
 0.11529117094552283,
 0.1095804633688165,
 0.10434564809016905,
 0.10927989981214775,
 0.11458985597996241,
 0.11559173450219157,
 0.12275516593613017,
 0.1206261740763932,
 0.12663744520976827,
 0.13134627426424544,
 0.12771446462116465,
 0.13046963055729488,
 0.13377582968065116,
 0.12884157795867246,
 0.12726361928616153,
 0.13507827175954912,
 0.13906073888541015,
 0.1454226675015654,
 0.14860363180964303,
 0.14725109580463364,
 0.14256731371321218,
 0.14482154038822787,
 0.13823418910457103,
 0.13515341264871633,
 0.1334001252348152,
 0.14707576706324355,
 0.14619912335629304,
 0.14624921728240442,
 0.14935504070131495,
 0.15226048841577955,
 0.14980588603631806,
 0.14572323105823415,
 0.14649968691296178,
 0.14259236067626796,
 0.14256731371321218,
 0.15421415153412643,
 0.15739511584220411,
 0.15716969317470253,
 0.1545397620538509,
 0.15180964308077638,
 0.1476518472135253,
 0.16713838447088286,
 0.16696305572949277,
 0.16262993112085156,
 0.16710081402629928,
 0.16758922980588598,
 0.16463368816530988,
 0.1633813400125234,
 0.1633813400125234,
 0.16493425172197868,
 0.17084533500313087,
 0.17112085159674384,
 0.1687163431433938,
 0.16210394489668123,
 0.16280525986224165,
 0.1656856606136506,
 0.17179711959924854,
 0.17648090169067,
 0.17635566687539134,
 0.1834690043832185,
 0.1856230432060112,
 0.18219160926737632,
 0.18126487163431432,
 0.1777833437695679,
 0.18467125860989347,
 0.18564809016906697,
 0.19273638071383836,
 0.1915341264871634,
 0.19313713212273004,
 0.19829680651221032,
 0.1955666875391358,
 0.1957921102066374,
 0.1931621790857858,
 0.2007764558547276]
Prediction for next 30 days
lst_output = []
n_steps = 100
i = 0
while(i<30):
    if(len(temp_input)>100):
        x_input = np.array(temp_input[1:])
        print("{} day input {}".format(i,x_input))
        x_input = x_input.reshape(1,-1)
        x_input = x_input.reshape(1,n_steps,1)
        yhat = model.predict(x_input,verbose = 0)
        print("{} day output {}".format(i,yhat))
        temp_input.extend(yhat[0].tolist())
        temp_input = temp_input[1:]
        lst_output.extend(yhat.tolist())
        i = i+1
    else:
        x_input = x_input.reshape(1,n_steps,1)
        yhat = model.predict(x_input, verbose=0)
        print(yhat[0])
        temp_input.extend(yhat[0].tolist())
        print(len(temp_input))
        lst_output.extend(yhat.tolist())
        i = i+1
        
print(lst_output)
[0.19835041]
101
1 day input [0.09380088 0.09665623 0.11015654 0.11937383 0.11243582 0.11974953
 0.11291171 0.11028178 0.11063244 0.11774577 0.11611772 0.12145272
 0.11739512 0.11448967 0.10429555 0.10537257 0.10659987 0.09986224
 0.10289292 0.10161553 0.09635567 0.09785848 0.11068253 0.11769568
 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986
 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446
 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074
 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419
 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504
 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731
 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185
 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369
 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634
 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567
 0.183469   0.18562304 0.18219161 0.18126487 0.17778334 0.18467126
 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669
 0.19579211 0.19316218 0.20077646 0.19835041]
1 day output [[0.1995855]]
2 day input [0.09665623 0.11015654 0.11937383 0.11243582 0.11974953 0.11291171
 0.11028178 0.11063244 0.11774577 0.11611772 0.12145272 0.11739512
 0.11448967 0.10429555 0.10537257 0.10659987 0.09986224 0.10289292
 0.10161553 0.09635567 0.09785848 0.11068253 0.11769568 0.11211021
 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173
 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963
 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267
 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341
 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049
 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415
 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838
 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134
 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394
 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567 0.183469
 0.18562304 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809
 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211
 0.19316218 0.20077646 0.19835041 0.1995855 ]
2 day output [[0.20065735]]
3 day input [0.11015654 0.11937383 0.11243582 0.11974953 0.11291171 0.11028178
 0.11063244 0.11774577 0.11611772 0.12145272 0.11739512 0.11448967
 0.10429555 0.10537257 0.10659987 0.09986224 0.10289292 0.10161553
 0.09635567 0.09785848 0.11068253 0.11769568 0.11211021 0.11529117
 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517
 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583
 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363
 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341 0.13340013
 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589
 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512
 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306
 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134
 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526
 0.16568566 0.17179712 0.1764809  0.17635567 0.183469   0.18562304
 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638
 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218
 0.20077646 0.19835041 0.1995855  0.20065735]
3 day output [[0.20159736]]
4 day input [0.11937383 0.11243582 0.11974953 0.11291171 0.11028178 0.11063244
 0.11774577 0.11611772 0.12145272 0.11739512 0.11448967 0.10429555
 0.10537257 0.10659987 0.09986224 0.10289292 0.10161553 0.09635567
 0.09785848 0.11068253 0.11769568 0.11211021 0.11529117 0.10958046
 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617
 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158
 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511
 0.14256731 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577
 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323
 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969
 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993
 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425
 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566
 0.17179712 0.1764809  0.17635567 0.183469   0.18562304 0.18219161
 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413
 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646
 0.19835041 0.1995855  0.20065735 0.20159736]
4 day output [[0.20243767]]
5 day input [0.11243582 0.11974953 0.11291171 0.11028178 0.11063244 0.11774577
 0.11611772 0.12145272 0.11739512 0.11448967 0.10429555 0.10537257
 0.10659987 0.09986224 0.10289292 0.10161553 0.09635567 0.09785848
 0.11068253 0.11769568 0.11211021 0.11529117 0.10958046 0.10434565
 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617 0.12663745
 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362
 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731
 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912
 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969
 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976
 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081
 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534
 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712
 0.1764809  0.17635567 0.183469   0.18562304 0.18219161 0.18126487
 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713
 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041
 0.1995855  0.20065735 0.20159736 0.20243767]
5 day output [[0.20320483]]
6 day input [0.11974953 0.11291171 0.11028178 0.11063244 0.11774577 0.11611772
 0.12145272 0.11739512 0.11448967 0.10429555 0.10537257 0.10659987
 0.09986224 0.10289292 0.10161553 0.09635567 0.09785848 0.11068253
 0.11769568 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799
 0.11458986 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627
 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827
 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154
 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922
 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236
 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964
 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923
 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085
 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809
 0.17635567 0.183469   0.18562304 0.18219161 0.18126487 0.17778334
 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681
 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855
 0.20065735 0.20159736 0.20243767 0.20320483]
6 day output [[0.20391884]]
7 day input [0.11291171 0.11028178 0.11063244 0.11774577 0.11611772 0.12145272
 0.11739512 0.11448967 0.10429555 0.10537257 0.10659987 0.09986224
 0.10289292 0.10161553 0.09635567 0.09785848 0.11068253 0.11769568
 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986
 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446
 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074
 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419
 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504
 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731
 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185
 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369
 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634
 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567
 0.183469   0.18562304 0.18219161 0.18126487 0.17778334 0.18467126
 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669
 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735
 0.20159736 0.20243767 0.20320483 0.20391884]
7 day output [[0.20459381]]
8 day input [0.11028178 0.11063244 0.11774577 0.11611772 0.12145272 0.11739512
 0.11448967 0.10429555 0.10537257 0.10659987 0.09986224 0.10289292
 0.10161553 0.09635567 0.09785848 0.11068253 0.11769568 0.11211021
 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173
 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963
 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267
 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341
 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049
 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415
 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838
 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134
 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394
 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567 0.183469
 0.18562304 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809
 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211
 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736
 0.20243767 0.20320483 0.20391884 0.20459381]
8 day output [[0.2052401]]
9 day input [0.11063244 0.11774577 0.11611772 0.12145272 0.11739512 0.11448967
 0.10429555 0.10537257 0.10659987 0.09986224 0.10289292 0.10161553
 0.09635567 0.09785848 0.11068253 0.11769568 0.11211021 0.11529117
 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517
 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583
 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363
 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341 0.13340013
 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589
 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512
 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306
 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134
 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526
 0.16568566 0.17179712 0.1764809  0.17635567 0.183469   0.18562304
 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638
 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218
 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767
 0.20320483 0.20391884 0.20459381 0.2052401 ]
9 day output [[0.20586526]]
10 day input [0.11774577 0.11611772 0.12145272 0.11739512 0.11448967 0.10429555
 0.10537257 0.10659987 0.09986224 0.10289292 0.10161553 0.09635567
 0.09785848 0.11068253 0.11769568 0.11211021 0.11529117 0.10958046
 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617
 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158
 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511
 0.14256731 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577
 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323
 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969
 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993
 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425
 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566
 0.17179712 0.1764809  0.17635567 0.183469   0.18562304 0.18219161
 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413
 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646
 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483
 0.20391884 0.20459381 0.2052401  0.20586526]
10 day output [[0.20647523]]
11 day input [0.11611772 0.12145272 0.11739512 0.11448967 0.10429555 0.10537257
 0.10659987 0.09986224 0.10289292 0.10161553 0.09635567 0.09785848
 0.11068253 0.11769568 0.11211021 0.11529117 0.10958046 0.10434565
 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617 0.12663745
 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362
 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731
 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912
 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969
 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976
 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081
 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534
 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712
 0.1764809  0.17635567 0.183469   0.18562304 0.18219161 0.18126487
 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713
 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041
 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483 0.20391884
 0.20459381 0.2052401  0.20586526 0.20647523]
11 day output [[0.20707469]]
12 day input [0.12145272 0.11739512 0.11448967 0.10429555 0.10537257 0.10659987
 0.09986224 0.10289292 0.10161553 0.09635567 0.09785848 0.11068253
 0.11769568 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799
 0.11458986 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627
 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827
 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154
 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922
 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236
 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964
 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923
 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085
 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809
 0.17635567 0.183469   0.18562304 0.18219161 0.18126487 0.17778334
 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681
 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855
 0.20065735 0.20159736 0.20243767 0.20320483 0.20391884 0.20459381
 0.2052401  0.20586526 0.20647523 0.20707469]
12 day output [[0.20766784]]
13 day input [0.11739512 0.11448967 0.10429555 0.10537257 0.10659987 0.09986224
 0.10289292 0.10161553 0.09635567 0.09785848 0.11068253 0.11769568
 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986
 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446
 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074
 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419
 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504
 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731
 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185
 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369
 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634
 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567
 0.183469   0.18562304 0.18219161 0.18126487 0.17778334 0.18467126
 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669
 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735
 0.20159736 0.20243767 0.20320483 0.20391884 0.20459381 0.2052401
 0.20586526 0.20647523 0.20707469 0.20766784]
13 day output [[0.2082582]]
14 day input [0.11448967 0.10429555 0.10537257 0.10659987 0.09986224 0.10289292
 0.10161553 0.09635567 0.09785848 0.11068253 0.11769568 0.11211021
 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173
 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963
 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267
 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341
 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049
 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415
 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838
 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134
 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394
 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567 0.183469
 0.18562304 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809
 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211
 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736
 0.20243767 0.20320483 0.20391884 0.20459381 0.2052401  0.20586526
 0.20647523 0.20707469 0.20766784 0.2082582 ]
14 day output [[0.20884879]]
15 day input [0.10429555 0.10537257 0.10659987 0.09986224 0.10289292 0.10161553
 0.09635567 0.09785848 0.11068253 0.11769568 0.11211021 0.11529117
 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517
 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583
 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363
 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341 0.13340013
 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589
 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512
 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306
 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134
 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526
 0.16568566 0.17179712 0.1764809  0.17635567 0.183469   0.18562304
 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638
 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218
 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767
 0.20320483 0.20391884 0.20459381 0.2052401  0.20586526 0.20647523
 0.20707469 0.20766784 0.2082582  0.20884879]
15 day output [[0.2094423]]
16 day input [0.10537257 0.10659987 0.09986224 0.10289292 0.10161553 0.09635567
 0.09785848 0.11068253 0.11769568 0.11211021 0.11529117 0.10958046
 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617
 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158
 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511
 0.14256731 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577
 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323
 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969
 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993
 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425
 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566
 0.17179712 0.1764809  0.17635567 0.183469   0.18562304 0.18219161
 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413
 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646
 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483
 0.20391884 0.20459381 0.2052401  0.20586526 0.20647523 0.20707469
 0.20766784 0.2082582  0.20884879 0.2094423 ]
16 day output [[0.21004081]]
17 day input [0.10659987 0.09986224 0.10289292 0.10161553 0.09635567 0.09785848
 0.11068253 0.11769568 0.11211021 0.11529117 0.10958046 0.10434565
 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617 0.12663745
 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362
 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731
 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912
 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969
 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976
 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081
 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534
 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712
 0.1764809  0.17635567 0.183469   0.18562304 0.18219161 0.18126487
 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713
 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041
 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483 0.20391884
 0.20459381 0.2052401  0.20586526 0.20647523 0.20707469 0.20766784
 0.2082582  0.20884879 0.2094423  0.21004081]
17 day output [[0.21064621]]
18 day input [0.09986224 0.10289292 0.10161553 0.09635567 0.09785848 0.11068253
 0.11769568 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799
 0.11458986 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627
 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827
 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154
 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922
 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236
 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964
 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923
 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085
 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809
 0.17635567 0.183469   0.18562304 0.18219161 0.18126487 0.17778334
 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681
 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855
 0.20065735 0.20159736 0.20243767 0.20320483 0.20391884 0.20459381
 0.2052401  0.20586526 0.20647523 0.20707469 0.20766784 0.2082582
 0.20884879 0.2094423  0.21004081 0.21064621]
18 day output [[0.21125978]]
19 day input [0.10289292 0.10161553 0.09635567 0.09785848 0.11068253 0.11769568
 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986
 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446
 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074
 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419
 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504
 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731
 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185
 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369
 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634
 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567
 0.183469   0.18562304 0.18219161 0.18126487 0.17778334 0.18467126
 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669
 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735
 0.20159736 0.20243767 0.20320483 0.20391884 0.20459381 0.2052401
 0.20586526 0.20647523 0.20707469 0.20766784 0.2082582  0.20884879
 0.2094423  0.21004081 0.21064621 0.21125978]
19 day output [[0.21188271]]
20 day input [0.10161553 0.09635567 0.09785848 0.11068253 0.11769568 0.11211021
 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173
 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963
 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267
 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341
 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049
 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415
 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838
 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134
 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394
 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567 0.183469
 0.18562304 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809
 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211
 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736
 0.20243767 0.20320483 0.20391884 0.20459381 0.2052401  0.20586526
 0.20647523 0.20707469 0.20766784 0.2082582  0.20884879 0.2094423
 0.21004081 0.21064621 0.21125978 0.21188271]
20 day output [[0.21251544]]
21 day input [0.09635567 0.09785848 0.11068253 0.11769568 0.11211021 0.11529117
 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517
 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583
 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363
 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341 0.13340013
 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589
 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512
 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306
 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134
 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526
 0.16568566 0.17179712 0.1764809  0.17635567 0.183469   0.18562304
 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638
 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218
 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767
 0.20320483 0.20391884 0.20459381 0.2052401  0.20586526 0.20647523
 0.20707469 0.20766784 0.2082582  0.20884879 0.2094423  0.21004081
 0.21064621 0.21125978 0.21188271 0.21251544]
21 day output [[0.21315862]]
22 day input [0.09785848 0.11068253 0.11769568 0.11211021 0.11529117 0.10958046
 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617
 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158
 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511
 0.14256731 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577
 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323
 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969
 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993
 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425
 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566
 0.17179712 0.1764809  0.17635567 0.183469   0.18562304 0.18219161
 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413
 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646
 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483
 0.20391884 0.20459381 0.2052401  0.20586526 0.20647523 0.20707469
 0.20766784 0.2082582  0.20884879 0.2094423  0.21004081 0.21064621
 0.21125978 0.21188271 0.21251544 0.21315862]
22 day output [[0.21381229]]
23 day input [0.11068253 0.11769568 0.11211021 0.11529117 0.10958046 0.10434565
 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617 0.12663745
 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362
 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731
 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912
 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969
 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976
 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081
 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534
 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712
 0.1764809  0.17635567 0.183469   0.18562304 0.18219161 0.18126487
 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713
 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041
 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483 0.20391884
 0.20459381 0.2052401  0.20586526 0.20647523 0.20707469 0.20766784
 0.2082582  0.20884879 0.2094423  0.21004081 0.21064621 0.21125978
 0.21188271 0.21251544 0.21315862 0.21381229]
23 day output [[0.21447644]]
24 day input [0.11769568 0.11211021 0.11529117 0.10958046 0.10434565 0.1092799
 0.11458986 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627
 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827
 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154
 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922
 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236
 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964
 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923
 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085
 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809
 0.17635567 0.183469   0.18562304 0.18219161 0.18126487 0.17778334
 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681
 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855
 0.20065735 0.20159736 0.20243767 0.20320483 0.20391884 0.20459381
 0.2052401  0.20586526 0.20647523 0.20707469 0.20766784 0.2082582
 0.20884879 0.2094423  0.21004081 0.21064621 0.21125978 0.21188271
 0.21251544 0.21315862 0.21381229 0.21447644]
24 day output [[0.2151507]]
25 day input [0.11211021 0.11529117 0.10958046 0.10434565 0.1092799  0.11458986
 0.11559173 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446
 0.13046963 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074
 0.14542267 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419
 0.13515341 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504
 0.15226049 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731
 0.15421415 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185
 0.16713838 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369
 0.16338134 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634
 0.16210394 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567
 0.183469   0.18562304 0.18219161 0.18126487 0.17778334 0.18467126
 0.18564809 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669
 0.19579211 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735
 0.20159736 0.20243767 0.20320483 0.20391884 0.20459381 0.2052401
 0.20586526 0.20647523 0.20707469 0.20766784 0.2082582  0.20884879
 0.2094423  0.21004081 0.21064621 0.21125978 0.21188271 0.21251544
 0.21315862 0.21381229 0.21447644 0.2151507 ]
25 day output [[0.2158347]]
26 day input [0.11529117 0.10958046 0.10434565 0.1092799  0.11458986 0.11559173
 0.12275517 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963
 0.13377583 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267
 0.14860363 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341
 0.13340013 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049
 0.14980589 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415
 0.15739512 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838
 0.16696306 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134
 0.16338134 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394
 0.16280526 0.16568566 0.17179712 0.1764809  0.17635567 0.183469
 0.18562304 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809
 0.19273638 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211
 0.19316218 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736
 0.20243767 0.20320483 0.20391884 0.20459381 0.2052401  0.20586526
 0.20647523 0.20707469 0.20766784 0.2082582  0.20884879 0.2094423
 0.21004081 0.21064621 0.21125978 0.21188271 0.21251544 0.21315862
 0.21381229 0.21447644 0.2151507  0.21583471]
26 day output [[0.21652813]]
27 day input [0.10958046 0.10434565 0.1092799  0.11458986 0.11559173 0.12275517
 0.12062617 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583
 0.12884158 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363
 0.1472511  0.14256731 0.14482154 0.13823419 0.13515341 0.13340013
 0.14707577 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589
 0.14572323 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512
 0.15716969 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306
 0.16262993 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134
 0.16493425 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526
 0.16568566 0.17179712 0.1764809  0.17635567 0.183469   0.18562304
 0.18219161 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638
 0.19153413 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218
 0.20077646 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767
 0.20320483 0.20391884 0.20459381 0.2052401  0.20586526 0.20647523
 0.20707469 0.20766784 0.2082582  0.20884879 0.2094423  0.21004081
 0.21064621 0.21125978 0.21188271 0.21251544 0.21315862 0.21381229
 0.21447644 0.2151507  0.21583471 0.21652813]
27 day output [[0.21723023]]
28 day input [0.10434565 0.1092799  0.11458986 0.11559173 0.12275517 0.12062617
 0.12663745 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158
 0.12726362 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511
 0.14256731 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577
 0.14619912 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323
 0.14649969 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969
 0.15453976 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993
 0.16710081 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425
 0.17084534 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566
 0.17179712 0.1764809  0.17635567 0.183469   0.18562304 0.18219161
 0.18126487 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413
 0.19313713 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646
 0.19835041 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483
 0.20391884 0.20459381 0.2052401  0.20586526 0.20647523 0.20707469
 0.20766784 0.2082582  0.20884879 0.2094423  0.21004081 0.21064621
 0.21125978 0.21188271 0.21251544 0.21315862 0.21381229 0.21447644
 0.2151507  0.21583471 0.21652813 0.21723023]
28 day output [[0.21794063]]
29 day input [0.1092799  0.11458986 0.11559173 0.12275517 0.12062617 0.12663745
 0.13134627 0.12771446 0.13046963 0.13377583 0.12884158 0.12726362
 0.13507827 0.13906074 0.14542267 0.14860363 0.1472511  0.14256731
 0.14482154 0.13823419 0.13515341 0.13340013 0.14707577 0.14619912
 0.14624922 0.14935504 0.15226049 0.14980589 0.14572323 0.14649969
 0.14259236 0.14256731 0.15421415 0.15739512 0.15716969 0.15453976
 0.15180964 0.14765185 0.16713838 0.16696306 0.16262993 0.16710081
 0.16758923 0.16463369 0.16338134 0.16338134 0.16493425 0.17084534
 0.17112085 0.16871634 0.16210394 0.16280526 0.16568566 0.17179712
 0.1764809  0.17635567 0.183469   0.18562304 0.18219161 0.18126487
 0.17778334 0.18467126 0.18564809 0.19273638 0.19153413 0.19313713
 0.19829681 0.19556669 0.19579211 0.19316218 0.20077646 0.19835041
 0.1995855  0.20065735 0.20159736 0.20243767 0.20320483 0.20391884
 0.20459381 0.2052401  0.20586526 0.20647523 0.20707469 0.20766784
 0.2082582  0.20884879 0.2094423  0.21004081 0.21064621 0.21125978
 0.21188271 0.21251544 0.21315862 0.21381229 0.21447644 0.2151507
 0.21583471 0.21652813 0.21723023 0.21794063]
29 day output [[0.21865852]]
[[0.19835041463375092], [0.19958549737930298], [0.20065735280513763], [0.20159736275672913], [0.20243766903877258], [0.20320482552051544], [0.20391884446144104], [0.20459380745887756], [0.20524010062217712], [0.2058652639389038], [0.20647522807121277], [0.20707468688488007], [0.20766784250736237], [0.20825819671154022], [0.20884878933429718], [0.20944230258464813], [0.21004080772399902], [0.21064621210098267], [0.21125978231430054], [0.21188271045684814], [0.2125154435634613], [0.21315862238407135], [0.21381229162216187], [0.21447643637657166], [0.21515069901943207], [0.21583470702171326], [0.21652813255786896], [0.21723023056983948], [0.21794062852859497], [0.21865852177143097]]
day_new = np.arange(1,101)
day_pred = np.arange(101,131)
len(df1)
1257
#1157 came from len(df1)-100   that is 1257-100 = 1157
plt.plot(day_new,scaler.inverse_transform(df1[1157:]))
plt.plot(day_pred,scaler.inverse_transform(lst_output))
[<matplotlib.lines.Line2D at 0x1c883380760>]

#combined data plotted with prediction
df3 = df1.tolist()
df3.extend(lst_output)
plt.plot(df3[1000:])
[<matplotlib.lines.Line2D at 0x1c8832b86a0>]

 
